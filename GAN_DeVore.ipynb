{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "\n",
    "In this notebook, we'll be building a generative adversarial network (GAN) trained on the MNIST dataset. Using this network, we will be generated new digits!\n",
    "\n",
    "The idea behind GANs is that you have two networks, a generator $G$ and a discriminator $D$, competing against each other. The generator makes fake data to pass to the discriminator. The discriminator also sees real data and predicts if the data it's received is real or fake. The generator is trained to fool the discriminator, it wants to output data that looks _as close as possible_ to real data. And the discriminator is trained to figure out which data is real and which is fake. What ends up happening is that the generator learns to make data that is indistiguishable from real data to the discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator network\n",
    "\n",
    "Here we'll build the generator network. We will use a leaky ReLU to allow gradients to flow backwards through the layer unimpeded. A leaky ReLU is like a normal ReLU, except that there is a small non-zero output for negative input values.\n",
    "\n",
    "#### Leaky ReLU\n",
    "Typically, a parameter `alpha` sets the magnitude of the output for negative values. So, the output for negative input (`x`) values is `alpha*x`, and the output for positive `x` is `x`:\n",
    "$$\n",
    "f(x) = max(\\alpha * x, x)\n",
    "$$\n",
    "For implementing the leaky relu, you could use the following resource https://keras.io/layers/advanced-activations/\n",
    "\n",
    "#### Tanh Output\n",
    "The generator has been found to perform the best with $tanh$ for the generator output. This means that we'll have to rescale the MNIST images to be between -1 and 1, instead of the usual 0 and 1 range. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "\n",
    "The discriminator network is almost exactly the same as the generator network, except that we're using a sigmoid output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build network\n",
    "\n",
    "Now we're are going to build the generator and discrimator networks.\n",
    "\n",
    "We'll create the generator, `generator(input_z, input_size)`. This builds the generator with the appropriate input and output sizes.\n",
    "\n",
    "Then the discriminators. We'll build two of them, one for real data and one for fake data. Since we want the weights to be the same for both real and fake data, we need to reuse the variables. For the fake data, we're getting it from the generator as `g_model`. So the real data discriminator is `discriminator(input_real)` while the fake discriminator is `discriminator(g_model, reuse=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "from tqdm import tqdm\n",
    "from __future__ import print_function, division\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Conv2D, UpSampling2D, Conv2DTranspose\n",
    "from keras.layers.core import Reshape, Dense, Dropout, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras import backend as K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST data\n",
    "def load_data(path='mnist.npz'):\n",
    "    \"\"\"Loads the MNIST dataset.\n",
    "    # Arguments\n",
    "        path: path where to cache the dataset locally\n",
    "            (relative to ~/.keras/datasets).\n",
    "    # Returns\n",
    "        Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
    "    \"\"\"\n",
    "    path = \"mnist.npz\"\n",
    "    f = np.load(path)\n",
    "    x_train, y_train = f['x_train'], f['y_train']\n",
    "    x_test, y_test = f['x_test'], f['y_test']\n",
    "    f.close()\n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator\n",
    "def build_generator(latent_dim):\n",
    "    # Make sure to use a tanh activation at the last layer and compile the model before returning it\n",
    "    # For upsampling the image, you could use UpSampling2D function from Keras library. \n",
    "    # Use adam optimizer with: adam = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # Prepare model for inputs of shape latent_dim\n",
    "    generator_input = Input(shape=(latent_dim,))\n",
    "    \n",
    "    # Build model to mimic CIFAR10 example from textbook (with correct sizes for MNINST image - 28x28x1)\n",
    "    x = Dense(32 * 14 * 14)(generator_input)\n",
    "    \n",
    "    # Reshape to 14x14x32\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Reshape((14, 14, 32))(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    # Upsample to 28x28 (MNIST image resolution)\n",
    "    x = Conv2DTranspose(64, 4, strides=2, padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(64, 3, padding='same')(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    # Decrease to proper image size (28x28x1)    \n",
    "    x = Conv2D(1, 3, activation='tanh', padding='same')(x)\n",
    "    \n",
    "    generator = Model(generator_input, x)\n",
    "    generator.summary()\n",
    "    \n",
    "    adam = Adam(0.0002, 0.5)    \n",
    "    # Compile model\n",
    "    generator.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "def build_discriminator(img_shape):\n",
    "    # Make sure to use a sigmoid at the last layer and compile the model before returning it\n",
    "    # Use adam optimizer with adam = Adam(0.0002, 0.5)\n",
    "    img_rows, img_cols, channels = img_shape\n",
    "    \n",
    "    # Accept inputs of 28x28x1\n",
    "    discriminator_input = Input(shape=(img_rows, img_cols, channels))\n",
    "    \n",
    "    x = Conv2D(32, 4)(discriminator_input)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Conv2D(32, 4, strides=1)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(32, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Conv2D(32, 4, strides=2)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dropout(0.4)(x) # May need to tweak this\n",
    "    \n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    discriminator = Model(discriminator_input, x)\n",
    "    discriminator.summary()\n",
    "    \n",
    "    adam = Adam(0.0002, 0.5)\n",
    "    \n",
    "    # Compile model\n",
    "    discriminator.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now that we've built the disriminator and generator, lets combine the two for the full end to end system.\n",
    "# This is where we are calculating D(G(z))!\n",
    "# We will set up a Model object to train the generator to fool the discriminator. We need to turn of\n",
    "# weight updates for the discriminator, create an Input object for the generator with the right\n",
    "# dimension, run that through the generator, and run the output of the generator through the discriminator. \n",
    "# You should compile this new Model object.\n",
    "def build_gan(discriminator, generator, latent_dim):\n",
    "    \n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    gan_output = discriminator(generator(gan_input))\n",
    "    \n",
    "    gan = Model(gan_input, gan_output)\n",
    "    \n",
    "    adam = Adam(0.0002, 0.5)\n",
    "    \n",
    "    gan.compile(optimizer=adam, loss='binary_crossentropy')\n",
    "    \n",
    "    return gan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for our mnist dataset. \n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "# Feel free to change the order of channels, rows, and cols if you go ahead with a different order \n",
    "# in your discriminator and generator. \n",
    "# img_shape = (channels, img_rows, img_cols)\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a wall of generated MNIST images\n",
    "def plotGeneratedImages(epoch, generator, examples=100, dim=(10, 10), figsize=(10, 10)):\n",
    "    noise = np.random.normal(0, 1, size=[examples, latent_dim])\n",
    "    generatedImages = generator.predict(noise)\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generatedImages.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        # Reshape image\n",
    "        image = generatedImages[i].reshape(28,28)\n",
    "        plt.imshow(image, interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/dcgan_generated_image_epoch_DeVore_final_%d.png' % epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 25, 25, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 32)        16416     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 22, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 32)        16416     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 32)          16416     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 50,305\n",
      "Trainable params: 50,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 28, 28, 64)        65600     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "=================================================================\n",
      "Total params: 792,001\n",
      "Trainable params: 792,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:32<00:00, 20.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.60331225\n",
      "adversarial loss: 0.86873764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1875 [00:00<02:00, 15.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 2 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:30<00:00, 20.82it/s]\n",
      "  0%|          | 3/1875 [00:00<01:27, 21.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.5174006\n",
      "adversarial loss: 1.0115827\n",
      "--------------- Epoch 3 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.90it/s]\n",
      "  0%|          | 3/1875 [00:00<01:28, 21.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.4913813\n",
      "adversarial loss: 1.0878357\n",
      "--------------- Epoch 4 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:30<00:00, 20.81it/s]\n",
      "  0%|          | 3/1875 [00:00<01:29, 20.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.5663186\n",
      "adversarial loss: 0.9296609\n",
      "--------------- Epoch 5 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:30<00:00, 20.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.5594814\n",
      "adversarial loss: 0.98968416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1875 [00:00<01:58, 15.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 6 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.86it/s]\n",
      "  0%|          | 3/1875 [00:00<01:29, 20.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.5501053\n",
      "adversarial loss: 0.9014426\n",
      "--------------- Epoch 7 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.85it/s]\n",
      "  0%|          | 3/1875 [00:00<01:29, 20.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.54522526\n",
      "adversarial loss: 0.86188567\n",
      "--------------- Epoch 8 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:30<00:00, 20.76it/s]\n",
      "  0%|          | 3/1875 [00:00<01:28, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.54309314\n",
      "adversarial loss: 0.9855986\n",
      "--------------- Epoch 9 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.89it/s]\n",
      "  0%|          | 3/1875 [00:00<01:29, 20.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.593326\n",
      "adversarial loss: 0.867559\n",
      "--------------- Epoch 10 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [01:29<00:00, 20.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "discriminator loss: 0.5853712\n",
      "adversarial loss: 0.97934216\n"
     ]
    }
   ],
   "source": [
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "\n",
    "# Build and compile the generator\n",
    "generator = build_generator(latent_dim)\n",
    "\n",
    "# Build and compile the combined network\n",
    "gan = build_gan(discriminator, generator, latent_dim)\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "save_interval = 50\n",
    "\n",
    "# Load MNIST data and rescale -1 to 1\n",
    "(X_train, y_train), (X_test, y_test) = load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_train = X_train[:, np.newaxis, :, :]\n",
    "# Reshape images\n",
    "X_train = X_train.reshape((X_train.shape[0],) + img_shape)\n",
    "\n",
    "# Store losses\n",
    "dloss_vec = []\n",
    "gloss_vec = []\n",
    "\n",
    "batchCount = X_train.shape[0] / batch_size\n",
    "for e in range(1, epochs+1):\n",
    "    start = 0\n",
    "    print('-'*15, 'Epoch %d' % e, '-'*15)\n",
    "    for c in tqdm(range(int(batchCount))):\n",
    "        \n",
    "        # Get a random sample from real images, and from random noise\n",
    "        # Sample from normal distribution, size should be 128x100\n",
    "        noise = np.random.normal(size=(batch_size, latent_dim))\n",
    "        # Keep track on position in training set, sample next 128 images\n",
    "        stop = start + batch_size\n",
    "        imageBatch = X_train[start:stop]\n",
    "        start += batch_size\n",
    "\n",
    "        # Generate fake MNIST images, from noise\n",
    "        generatedImages = generator.predict(noise)\n",
    "        \n",
    "        # Lets train the discriminator first. \n",
    "        # We will concatenate the real images and fake images into a variable X\n",
    "        X = np.concatenate([generatedImages, imageBatch])\n",
    "\n",
    "        # Create the labels for fake and real data, composed of 0s and 1s\n",
    "        # Note that ones are for fake images, and zeros are for real images\n",
    "        yDis = np.concatenate([np.ones((batch_size,1)), np.zeros((batch_size,1))])\n",
    "        # Consider adding noise to labels\n",
    "        yDis += 0.05 * np.random.random(yDis.shape)\n",
    "\n",
    "        # Train discriminator\n",
    "        discriminator.trainable = True\n",
    "        dloss = discriminator.train_on_batch(X, yDis)\n",
    "\n",
    "        # Now lets train the generator\n",
    "        # Generate batch_size sized random noise \n",
    "        noise = np.random.normal(size=(batch_size, latent_dim))\n",
    "        \n",
    "        # Generate the labels for the generator\n",
    "        # These labels should all be for 'real' images\n",
    "        yGen = np.zeros((batch_size,1))\n",
    "        discriminator.trainable = False\n",
    "        gloss = gan.train_on_batch(noise, yGen)\n",
    "        \n",
    "    # Try printing loss and saving weights after each epoch\n",
    "    gan.save_weights('gan.h5')\n",
    "    print('discriminator loss:', dloss)\n",
    "    print('adversarial loss:', gloss)\n",
    "    dloss_vec.append(dloss)\n",
    "    gloss_vec.append(gloss)\n",
    "        \n",
    "    if e == 1 or e % 5 == 0:\n",
    "        # Save after certain epochs\n",
    "        plotGeneratedImages(e, generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Please embed some of the images you have generated and turn them in with your notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we post some images, let's take a look at how the loss functions changed over the 10 epochs. Since there are two loss functions, the model won't converge to a single minimum, rather the two loss functions will achieve a balance where neither one is changing drastically between each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT8AAAEyCAYAAACMONd1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VGXax/HvnUYIkNARCCUiVYqQ\n0ARBxQKooCIgKoIN8RVdXXXtZXFd111XXcva24rCUiygCBZcC0pJ6F2KkNASAiEQSH/eP54goSWT\n5ExOZs79uS4uMjNnzrkHkl9Oec5zizEGpZTymhC3C1BKKTdo+CmlPEnDTynlSRp+SilP0vBTSnmS\nhp9SypM0/JRSnqThp5TyJA0/pZQnhbm14fr165uWLVu6tXmlVJBKSkraY4xpUNpyroVfy5YtSUxM\ndGvzSqkgJSJbfVlOD3uVUp6k4aeU8qRSw09E3hGRVBFZdYrX24nILyKSIyL3Ol+iUko5z5dzfu8B\nLwP/OcXre4E7gcsdqkkpVUZ5eXmkpKSQnZ3tdimVJjIyktjYWMLDw8v1/lLDzxjzg4i0LOH1VCBV\nRC4pVwVKqQpLSUmhVq1atGzZEhFxuxy/M8aQnp5OSkoKcXFx5VpHpZ7zE5FxIpIoIolpaWmVuWml\nglp2djb16tXzRPABiAj16tWr0J5upYafMeYNY0yCMSahQYNSh+EopcrAK8F3REU/r17tVUp5kmuD\nnJVSwe2JJ56gZs2arFq1iksvvZSrrrrK7ZKOUWr4ichk4FygvoikAI8D4QDGmNdE5DQgEYgGCkXk\nLqCDMSbTb1UHo0N7Ye9miE1wuxKlPKHUw15jzChjTGNjTLgxJtYY87Yx5jVjzGtFr+8qej7aGFO7\n6GsNvrI4vA/eHQxvXQB7t7hdjVLl9tRTT9GmTRv69u3L+vXrT3j922+/pWvXrnTq1Ikbb7yRnJwc\nAB544AE6dOhA586dufdeO1x42rRpdOzYkS5dutCvXz/Ha9XDXrflZcOUayF9I4SEwuK34OKn3K5K\nBbA/z1rNmh3O7n90aBLN45edWeIySUlJTJkyhWXLlpGfn0+3bt2Ij4///fXs7GzGjh3Lt99+S5s2\nbbj++ut59dVXGT16NJ988gnr1q1DRMjIyABg4sSJzJ07l6ZNm/7+nJP0goebCgvgk3GwdT5c8Rp0\nuByWfAA5B92uTKky+/HHH7niiiuIiooiOjqaIUOGHPP6+vXriYuLo02bNgCMGTOGH374gZiYGCIj\nI7npppv4+OOPiYqKAqBPnz6MHTuWN998k4KCAsfr1T0/txgDcx6ENZ/BRU9Bp6ugdgtYNR1WTIHu\nN7tdoQpQpe2hVTVhYWEsWrSIb7/9lunTp/Pyyy8zb948XnvtNRYuXMgXX3xBfHw8SUlJ1KtXz7Ht\n6p6fW35+ERa9Dr0nwNkT7HOxCdCkGyx8HQoL3a1PqTLq168fn376KYcPH+bAgQPMmjXrmNfbtm3L\nb7/9xsaNGwH44IMP6N+/PwcPHmT//v0MHjyY559/nuXLlwOwadMmevbsycSJE2nQoAHJycmO1qt7\nfm5Y/l/4+jHoOAwufPLo8yLQc7w9FN78HZwxwL0alSqjbt26MXLkSLp06ULDhg3p3r37Ma9HRkby\n7rvvMnz4cPLz8+nevTvjx49n7969DB06lOzsbIwxPPfccwDcd999/PrrrxhjGDBgAF26dHG0XjHG\nOLpCXyUkJBhPTma6aR58OBya94brZkBYtWNfz8+FFzpC47Pg2qnu1KgCztq1a2nfvr3bZVS6k31u\nEUkyxpQ6ZkwPeyvTzuXw39FQvy1c/eGJwQcQFgEJN8KvcyF9U+XXqJRHaPhVln2/2T2+6nXguukQ\nGXPqZeNvgJBwWPRmpZWnlNdo+FWGrHSYNAzyc+yhbnSTkpev1Qg6XglLJ0HOgcqpUSmP0fDzt9xD\nMHkkZCTDqCnQoK1v7+t5K+QegGWT/VufUh6l4edPBfkw4yZISYRhb0GL3r6/t2k8xHa3w2F02ItS\njtPw8xdjYPY9sH42DP4HdBhS+nuO13O8ve1t0zzn61PK4zT8/OWHf0DSe9D3j9DjlvKto/0QqHka\nLHzV0dKUqkxjx45l+vTpbpdxAg0/f1jyAXz3FHQZBQMeK/96wiKg+02w8RvY86tz9SmlNPwct2Eu\nzPoDtBoAQ16yd21URPxYCI2ARW84Up5S/vTkk0/Stm1b+vbty6hRo3j22WePeV2ntApWKUkwbSyc\n1glGvA+h5Wupd4yaDe1tcMs+gvMfKXl8oFIAXz4Au1Y6u87TOsGgv5W4yOLFi5kxYwbLly8nLy9P\np7TyjPRN8NFwqNEArp0G1Wo5t+6et0LuQRuASlVR8+fPZ+jQoURGRlKrVi0uu+yyY17XKa2C0cFU\nmHSl/Xr0J3ZvzUlNukKzXna2lx63Qoj+zlIlKGUPrarRKa0CVc5Be9vawVS4ZhrUa+Wf7fS8FfZt\ngY1f+2f9SlVQnz59mDVrFtnZ2Rw8eJDPP//8mNd1SqtgUpAHU6+351dGTYbY+NLfU17tL4NaTWDh\na9DmYv9tR6ly6t69O0OGDKFz5840atSITp06ERNz9Bx1VZvSCmOMK3/i4+NNQCssNObj8cY8Hm1M\n4nuVs83v/2G3l7qucranAsaaNWvcLsEYY8yBAweMMcZkZWWZ+Ph4k5SU5NftnexzA4nGhwzSw97y\nmvckLP8Izn0I4sdUzjbjx0JoNR32oqqscePGcdZZZ9GtWzeGDRtGt27d3C7plPSwtzwWvQk//hO6\njYH+f6q87daoD52G28kOzn8UqteuvG0r5YOPPgqcEQm651dWa2fB7PugzSC45LmKD2Iuq57jIC/L\nTnelVDHGpVnZ3VLRz6vhVxbbFsCMm+2MK1e9A6Eu7Dg37gLNz7aHvoXOj31SgSkyMpL09HTPBKAx\nhvT0dCIjI8u9Dj3s9VXaevhoJMTEwjVTISLKvVp63grTxthb6doNdq8OVWXExsaSkpJCWlqa26VU\nmsjISGJjY8v9fg0/X2TutDMxh0bYmZhrODfQslzaXQrRsXbYi4afAsLDw4mLi3O7jICih72lyd4P\nH14Fh/fZ29bqtHS7Inu43eNm2PI9pK51uxqlApKGX0nyc2DKtZC2DkZ+AE3Ocruio7qNgbBIe8ub\nUqrMNPxOpbAQPr0NfvsRhr4Crc53u6JjRdWFziNg+RS7V6qUKhMNv1P5/hlYNQMueAK6XO12NSfX\n41bIP2wnT1VKlYmG38lk7YGfX4Qzr4Q+d7ldzamd1hFanmMHXRfku12NUgGl1PATkXdEJFVEVp3i\ndRGRF0Vko4isEJGqez+Lrxa+BnmH4dwHKn8Qc1n1vBX2b4MNX7pdiVIBxZc9v/eAgSW8PghoXfRn\nHBDY3XayM2HhG9D+Ut977LqpzSCIaa4XPpQqo1LDzxjzA7C3hEWGAv8pmlBhAVBbRBo7VWClS3wH\ncvbbrmuB4Miwl99+hF0n3TlXSp2EE+f8mgLFZxlMKXou8OQdhl+Kruw2DaCj966jIay6bXCulPJJ\npV7wEJFxIpIoIolV8jacpZMgKxXOucftSsomqi50GQkrpsKhknbSlVJHOBF+24FmxR7HFj13AmPM\nG8aYBGNMQoMGDRzYtIMK8mD+i9CsJ7To43Y1ZddzPORnw5L33a5EqYDgRPjNBK4vuurbC9hvjNnp\nwHor18rp9qrpOfdU/Su8J9OwPcT1h0Vv6bAXpXzgy1CXycAvQFsRSRGRm0RkvIiML1pkNrAZ2Ai8\nCfyf36r1l8JC+Ok5aNQRWl/kdjXl13M8ZKbA+i/cruREGcnwyW16UUZVGaXO6mKMGVXK6wa43bGK\n3LDuc9izAYa9HZh7fUe0uRhqt7DDXjoMdbuao3attB3uDuyErfPh1u+heh23qwoOxgT296yL9A4P\nY+yU9HVPhzOvcLuaigkJhR7jbMDsXOF2NdamefDOIJAQGPIyZG63e4CFhW5XFvi++TO83g/yst2u\nJCBp+G2aBzuX2dvYQkLdrqbiul4H4VFVY9Dzssl2j692c7jpa+g2Gi7+q70bZf4LblcX2NI2wPx/\nwa4V8MvLblcTkDT8fnzO9sOtqpMXlFX12tBlFKycZu9RdoMx8MM/4NPx0OJsuPFLiCka+tljHHQc\nZrvfbfnBnfqCwTeP219ycf3t93Bm4F1jLFV+Dsz7i99mLfJ2+G1bAFt/grPvgLBqblfjnB7joCAH\nkt6r/G0X5MPnd9lv2k4j4NoZEHm0cTUicNmLUO8MmH4jZO6o/BoD3W/zYf1sOOduuOwFKMyDb//s\ndlXOm/+i/SW6fYlfVu/t8PvxOahet/L67laWhu3g9PNg8dt2/GJlyc2CKdfY0O37R7jyDQiLOHG5\najVhxAeQewim3VC5NQY6Y+CrR+zRSs/b7LnqXv8HyydDSqLb1Tln7xb48VnocDmcMcAvm/Bu+O1a\nCb/Otd84ETXcrsZ5PcfDgR221WZlOJgK710CG7+2LT0veLzkq5AN28GQFyF5AXz9eOXUGAxWfww7\nlsD5jxxtotXvXqjZCL68PzguJBkDX/4JQsJg4NN+24x3w++n5yGilp0UIBi1vgjqxFXOhY89G+Ht\nCyF1HVz9EXS/ybf3dbrKHqIveAVWf+rfGoNBfo69wtuo47HnqKvVggGPwfZEe6430K37An79Cs59\nEKKb+G0z3gy/9E2w+hP7Qxqs481CQuxcf8kLYMdS/21n20IbfDkHYewX0HZQ2d5/0VPQNAE+ux32\n/OqfGoPF4rcgYytcOPHEkQldroHGZ9kLITkH3anPCblZMOcBaHim/f71I2+G3/wXbBvK3oE9NrtU\nZ10DETXt/IT+sHYW/GeIvcJ801cQG1/2dYRFwIj37QWn/4623/zqRIf3wfd/tzMOnewcWEgIDHrG\nDiQP5GFEP/wD9ifDJf+E0HC/bsp74bd/ux1/1nU01GzodjX+FRljA3DVdHtOzkkL37Bh1aijHcNX\nr1X51xUTC8Pesl3yPr/bnvNRx/rxOdtG9cKJp16meS/oeBX8/BLs21p5tTkldZ2t/axroUVvv2/O\ne+H3y8tgCu3wFi/oMQ4Kcp0b9lJYCF89Cl/eZw9xx8yCGvUrvt5W58N5D8GK/0Li2xVfXzDJ2GbP\n3XYZBad1KnnZC/8MCHz9WKWU5hhjYPa99kilpIB3kLfCL2uPDYHOI6BOC7erqRz1W8MZF9hhL/m5\nFVtXfg58fLNt7tT9Zhg56egVRyeccy+ccSHMeRBSkpxbb6D79kl75fz8R0pfNiYW+t4Faz614wED\nxcrpdjbyCx535pepD7wVfkcaE/W92+1KKlfP8XBwF6ydWf51HM6AD64sauf5Zxj8rPO3A4aE2LGB\nNU+DaWN0YlaAHctg5VQ7JCvGxwnSz74TomNhzv1QWODf+pyQvR/mPgRN46Fb5Y259U74BVpjIie1\nGgB1W9nwL4+MZHjnYkheCFe+Zfcs/DWTSFRdewHk4G74+JbgGLdWXsbA149CVD37b+6riCh7+Ltr\nJSwNgJ7O856CrDR7kaMS76/3Tvglvh1YjYmcdGTYS8rish9O7lwBb11gb0Mb/TF0Hu6fGotr2g0G\n/g02fmOv/nnVr1/b+5/733/sLYK+6DgMmvWyh8zZ+/1TnxN2LIPFb9rTKE26VuqmvRF+gdqYyEld\nRtlB3WVpcrRpHrw72P42vnEOxPXzX33HS7gROl8N/3vahqDXFOTbixZ1T4f4G8r+fhEY9Dc4lG6H\nyFRFhYXwxT12z9aX85kO80b4LZ1kd6sDrTGRkyKjoeu1sOpjOLC79OWPn46q0Zn+r7E4Ebj0eTs9\n/4xb7KG3lyz7ENLWwgVPnPz+aF806Wr/zxe+bu/CqWqW/sfelXLRU3asaCUL/vAL9MZETuoxDgrz\nIendUy9T0nRUlS0iyk6AUJBnL4Dk57hTR2XLzYLv/gqxPaD9kIqt6/zHICwSvnrYmdqckrXH3tPd\noq8dfeGC4A+/QG9M5KR6rew9v4vfPnmQFJ+OqvPIE6ejckP9M+Dyf8P2JJhbxX6A/eWXV+zV+Yv+\nUvHv2VqN7MQHG+ZUrdMH3zwOuQftRQ6Xfi6DO/yCpTGRk3reansTHz+RQM7Bo9NRnXMPXPF6+Q+3\nnNZhCPSeYE+MrwiCG/dLcjDVztDc/jJo3tOZdfa6zU5yMeehqjF92LYF9lRU79vt7D4uCe7wO9KY\n6Jw/6l7fEa3Oh/ptYOGrR28jO5gK7196dDqqAY9VvX+vC56A5r1h1p2Qutbtavznf0/b/ssXODg5\naVg1uPgp2LMeEt9xbr3lUZBvL3JEx0K/P7laSvCGX/HGRB0ud7uaqkPEnvvbsdROfrlnox3KUtbp\nqCpbaDhc9a69/em/oyHngNsVOS9tAyS9b690V+Re6ZNpOxhOP9eeS3Rz8PiiN2D3KnslulpN9+og\nmMMv2BoTOanLKKgWbU+Cv32hPcFenumoKlt0Y7jqHdi7CWbeEXwTIHzzhO3L0f9+59ctAhc/DTmZ\nNgDdkLkDvnvKnoJqd6k7NRQTvOEXbI2JnFStpp3VJnlhxaajckPcOfawfPUn5b9jpSra+rNtNt/3\nLv/d29qoAyTcZAf8717jn22UZO7D9pzjoGeqxGmV4Ay/YG1M5KRz/mgnEqjodFRu6HOXPYz76hE7\nmWqgK96Xo9f/+Xdb5z1k9/rnPFC5e86bvrNT8J9zjz0VVQUEZ/gFa2MiJ9WoDwMerbQZNBwlApe/\namcwmTYWDqa5XVHFrP7EDuUp3pfDX6Lq2gDc8r3tAFcZ8nPsdFV1T4c+f6icbfog+MJv54rgbkyk\nrOq17QDow3thxk2BMXvJyeTn2LaTDc+svFM0CTdC/bb2MLQyBo7//CKkb7QzAYVH+n97Pgq+8Av2\nxkTqqMad7Q/Ulu/dO4lfUYvfhn2/wUUn6cvhL6HhMPCvsG8LLHjVv9va9xv84N8WlOUVXOG3Z2Pw\nNyZSx+o22l68+fFZWD/H7WrK5nAG/PB322P5jAsqd9tnXABtBtlbGX2517u8vrwfJBQurnq/nIIr\n/Oa/YC9wBHtjInWswf+w07t/Ms7uaQSKn56zAVhJ07af4OKn7GHvPD9tf91se1vdeQ+6d394CYIn\n/PZvh+VTvNGYSB0rvLo9/2eAqddDXrbbFZUuYxsseM2e52vc2Z0a6rWCXuNh6YfOtzfNzbJ7fQ07\n2JnEq6DgCb9fXgYM9LnT7UqUG+rGwRWvwc7l8KW7t035ZN5ffO/L4U/97rPz6X3p8NCXH561E4pc\n8pzfW1CWV3CE35HGRJ1G2PnnlDe1G2z7syx53+7NVFU7ltkudb1us8N13BQZYweNJy+w/VmckLa+\nUltQlpdP4SciA0VkvYhsFJEHTvJ6CxH5VkRWiMj/RKRy/0d/b0xUhj4HKjid9wi0PAe++KPtYVHV\nHNOXo4o00up6nT1n+vXjkHuoYusyxk5cEBHl7OQMflBq+IlIKPAKMAjoAIwSkQ7HLfYs8B9jTGdg\nIvC004WekpcbE6kThYbZ+38ja9sJEKpa/4qN35S/L4e/hITCwGcgM8WOyauIVTNsC8oBj0PNBs7U\n5ye+7Pn1ADYaYzYbY3KBKcDQ45bpAMwr+vq7k7zuP15uTKROrmZDGP6evajwen9Y90XVmAShsKBi\nfTn8qWUfOxbvpxdgf0r51nGkBWWTbhA/1tHy/MGX8GsKFG+gkFL0XHHLgSuLvr4CqCUi9Y5fkYiM\nE5FEEUlMS3PgliRtTKROpUVvGP0JhEbYSVo/uMJO2+WmZR9C6hq7V1RVJoot7sKJgLGHv+Xx3V/t\n3JCXPhcQMyk5dcHjXqC/iCwF+gPbgRPuNzLGvGGMSTDGJDRo4MAusTYmUiU5vT/cNt+2wdy+BF49\n217VPJxR+bXkZtn+tLE9oEPlHRiVSZ0WtuH5qul2cpCy2LncztXnQgvK8vIl/LYDzYo9ji167nfG\nmB3GmCuNMV2Bh4ue8+93WEGene5bGxOpkoSG26uqdy6Bbtfbi2MvdYPEdyv3fuBf/l3Ul+PJKjGd\n0yn1vcvOLvPl/b43jHe5BWV5+RJ+i4HWIhInIhHA1cDM4guISH0RObKuBwH/z5W9chrsT9bGRMo3\nNerDZS/ArT/Ym/o/vwve6G/n0fO3g6n27qN2l0LzXv7fXkVE1IAL/2wnAl4+2bf3LP0AUhbbhksu\ntKAsr1LDzxiTD0wA5gJrganGmNUiMlFEjvTVOxdYLyIbgEbAU36q1yossNNWaWMiVVaNO8MNs+0V\n4UP74N1BMO2G8p/k98X//uZ8Xw5/6jQcYrvbmaWzM0teNivddmJr0cd2/AsgPp3zM8bMNsa0Mca0\nMsY8VfTcY8aYmUVfTzfGtC5a5mZjjH/nyVn3OaT/qo2JVPmIQMdhMGGxHXKyfja8lAD/e8ZeRHNS\n2gY7AD/+BtuGMxCI2KEvWam2D05Jvnnc9lNxsQVleQXeHR7G2L0+bUykKioiyk7sOWExtLkY/vdX\neLmHbevp1NCYb//sv74c/hQbb3u9LPg37N188mW2LbSHvL1vh4btK7c+BwRe+B1pTNT37oC4nK4C\nQO3mMOJ9GPM5REbDtDHw/mWwa1XF1rv1Z3uU0vcPVX7A70kNeBxCwuGrR0987fcWlE1db0FZXoEX\nfj8+Z//BO2tjIuWwuHNg3Pf2EG73Knj9HPj8j+Vr9WiMDY1aTaBXgE6xFt0Y+t1jA3zz/459bfGb\nsHulHUbkcgvK8gqs8DumMVEVHCSqAl9omB2rdscS+3fSe/BiV3sLZUG+7+tZ/QlsT4TzH/Z/Xw5/\n6nU71G4Bcx48+vkzd9oxi2dcCO0vc7e+Cgis8DvSmKjb9W5XooJdVF07Ser4n+wV4i/vs3uCm78v\n/b35ucX6cozyf63+FB5ph7CkroEl79nnvnoYCnJh8N8D7iJHcYETftqYSLmhUQe4fiaMnGTv0vjP\nEJhybckzRie60JfDn9pfZmfKmfeUvRi0akaVakFZXoETftqYSLlFxAbA7YvsHQyb5tmrwt8+aQOx\nuMMZ8P0zcPq50KpqNewpNxEY+DRkZ9hWoXXiqlQLyvIKjPAryIMDu7QxkXJXeKSd+XhCInQYYpsm\nvZQAK6YdHRrze1+OKn4bW1md1gm6jQFMlWtBWV5iXJrqJyEhwSQmJvr+BmOgML/KTomtPGjbAnsP\n7M5l9h7zPn+wd4t0vNJOqR9s8nPtVfAqPoOSiCQZYxJKWy4w9vzA/hbV4FNVSfNecMt3MOQlOxB4\nyjX2+QC6ub9MwiKqfPCVRZjbBSgV0EJC7OiDDkNh/ov2IoDbfTmUTzT8lHJCZAwMOMmdEKrKCpzD\nXqWUcpCGn1LKkzT8lFKepOGnlPIkDT+llCdp+CmlPEnDTynlSRp+SilP0vBTSnmShp9SypM0/JRS\nnqThp5TyJA0/pZQnafgppTxJw08p5UkafkopT9LwU0p5koafUsqTNPyUUp6k4aeU8iSfwk9EBorI\nehHZKCIPnOT15iLynYgsFZEVIjLY+VKVUso5pYafiIQCrwCDgA7AKBHpcNxijwBTjTFdgauBfztd\nqFJKOcmXPb8ewEZjzGZjTC4wBRh63DIGiC76OgbY4VyJSinlPF/69jYFkos9TgF6HrfME8BXInIH\nUAO4wJHqlFLKT5y64DEKeM8YEwsMBj4QkRPWLSLjRCRRRBLT0tIc2rRSSpWdL+G3HWhW7HFs0XPF\n3QRMBTDG/AJEAvWPX5Ex5g1jTIIxJqFBgwblq1gppRzgS/gtBlqLSJyIRGAvaMw8bpltwAAAEWmP\nDT/dtVNKVVmlhp8xJh+YAMwF1mKv6q4WkYkiMqRosXuAW0RkOTAZGGuMMf4qWimlKsqXCx4YY2YD\ns4977rFiX68B+jhbmlJK+Y/e4aGU8iQNP6WUJ2n4KaU8ScNPKeVJGn5KKU/S8FNKeZKGn1LKkzT8\nlFKepOGnlPIkDT+llCdp+CmlPEnDTynlSRp+SilP0vBTSnmShp9SypM0/JRSnqThp5TyJA0/pZQn\nafgppTxJw08p5UkafkopT9LwU0p5koafUsqTNPyUUp6k4aeU8iQNP6WUJ2n4KaU8ScNPKeVJGn5K\nKU/S8FNKeZKGn1LKkzT8lFKepOGnlPIkn8JPRAaKyHoR2SgiD5zk9edFZFnRnw0ikuF8qUop5Zyw\n0hYQkVDgFeBCIAVYLCIzjTFrjixjjLm72PJ3AF39UKtSSjnGlz2/HsBGY8xmY0wuMAUYWsLyo4DJ\nThSnlFL+4kv4NQWSiz1OKXruBCLSAogD5p3i9XEikigiiWlpaWWtVSmlHOP0BY+rgenGmIKTvWiM\necMYk2CMSWjQoIHDm1ZKKd/5En7bgWbFHscWPXcyV6OHvEqpAOBL+C0GWotInIhEYANu5vELiUg7\noA7wi7MlKqWU80oNP2NMPjABmAusBaYaY1aLyEQRGVJs0auBKcYY459SlVLKOaUOdQEwxswGZh/3\n3GPHPX7CubKUUsq/9A4PpZQnafgppTxJw08p5UkafkopT9LwU0p5koafUsqTNPyUUp6k4aeU8iQN\nP6WUJ2n4KaU8ScNPKeVJGn5KKU/S8FNKeZKGn1LKkzT8lFKepOGnlPIkDT+llCdp+CmlPEnDTynl\nSRp+SilP0vBTSnmShp9SypM0/JRSnqThp5TyJA0/pZQnafgppTxJw08p5UkafkopT9LwU0p5koaf\nUsqTNPyUUp6k4aeU8iSfwk9EBorIehHZKCIPnGKZESKyRkRWi8hHzpaplFLOCittAREJBV4BLgRS\ngMUiMtMYs6bYMq2BB4E+xph9ItLQySLzCgqZOGsNnZrGMKJ7MydXrZTyKF/2/HoAG40xm40xucAU\nYOhxy9wCvGKM2QdgjEl1skgBtuzJ4pHPVrEiJcPJVSulPMqX8GsKJBd7nFL0XHFtgDYiMl9EFojI\nwJOtSETGiUiiiCSmpaX5XGRYaAgvjupKg5rVGP9BEnsO5vj8XqWUOhmnLniEAa2Bc4FRwJsiUvv4\nhYwxbxhjEowxCQ0aNCjTBurWiOD10fGkZ+Uy4aMl5BcUOlG3UsqjfAm/7UDxE22xRc8VlwLMNMbk\nGWO2ABuwYeiojk1j+OsVnVhx03KhAAARLklEQVSweS/PzFnn9OqVUiXYnHaQf33zK5MWbOW7dams\n33WAA9l5bpdVbqVe8AAWA61FJA4belcD1xy3zKfYPb53RaQ+9jB4s5OFHjEsPpYVKRm8+eMWOsXW\nZkiXJv7YjFKqmOlJKTz22SoO5Rac8FqtamE0qV2dJrUji/6uTtOiv5vUjqRRdCThoVVvVF2p4WeM\nyReRCcBcIBR4xxizWkQmAonGmJlFr10kImuAAuA+Y0y6v4p++JIOrNmZyf3TV9C6YU3aN47216aU\n8rSsnHwe/WwVHy/ZTs+4ujw/8ixCQ4TtGYfZ8fuf7N8fL0vOYN+hY/cGQwQaRR8Nxia1I204xhwN\nyujqYYhIpX42McZU6gaPSEhIMImJieV+f+qBbC598SeqR4Qy8/a+xESFO1idUmrNjkwmTF7Cb3uy\nuOP81tw5oDWhIaUH1KHcfHZkZLMj4zA79x9me9HXxcMy97hz9lERocX2GiN/D8YmtatzZtNooiN9\n//kWkSRjTEKpywVq+AEkbd3H1W/8Qt8z6vP2mO6E+PAfo5QqmTGGSQu28uQXa6ldPZx/Xd2V3q3q\nObb+wkJDelbu72G4vSgQd2QcZsd++9yeg7m/L/+fG3vQr43vF0h9DT9fzvlVWfEt6vD4ZWfyyKer\neOGbDfzxorZul6RUQNt/OI/7p69gzupdnNu2Af8c3oV6Nas5uo2QEKFBrWo0qFWNLs1OGBQCQHZe\nAbv220A8s0mMo9s/IqDDD+Dans1ZnpzBi/M20rFpDBedeZrbJSkVkJZs28cdHy1ld2Y2Dw1ux819\nT3ftaCoyPJSW9WvQsn4Nv22j6l2CKSMR4cnLO9I5NoY/Tl3OprSDbpekVEApLDS89v0mRrz2CyIw\nbXxvxvVrFfSnkQI+/MD+lnj1ungiwkK49YMkDubku12SUgFhz8Ecxr63mL99uY6LzmzEF3eeQ9fm\nddwuq1IERfgBNK1dnZev6crmtIPcN205bl3IUSpQ/LxxD4P/9SMLNqfzl8s78so13Yip7p1RE0ET\nfgBnt6rPg4Pa8+WqXbz6/Sa3y1GqSsovKOS5r9Zz7dsLqRUZxme39+G6Xi0qfZyd2wL+gsfxbj4n\njhXb9/Ps3PV0bBJTpkvkXpKbX8j8TXuoHh5Ko+hIGtaqRo1qQfftoI6zc/9h/jB5GYt+28tV8bFM\nHHomURHe/H8Puk8tIjwzrBMbdh3gzilLmTWhL83qRrldVpVSUGi4679Lmb1y1zHP16wWRsPoajSq\nFWn/LgrFhtGRNKpV9Di6mmd/WALdt2t3c++05eTkF/L8yC5c0TXW7ZJcFZTfxVERYbw+Op4hL//E\nrR8kMeO2s6keEep2WVWCMYbHZ65i9spd3HtRG7o2r0PqgWx2Z+awOzOb1MwcUg9ks3RbBrszs8nJ\nP3H2nFpHQrIoHG0oRtIouhoNax39W//Nq4bc/EKembOOt3/aQofG0bx8TVdOb1DT7bJcF5ThB9Cy\nfg3+dXVXbnx/MQ9/spJ/jujiuXMaJ/PitxuZtGAb4/u3YsL5JU+8Y4wh83D+MeG4+8DRgNydmUPi\n1n2kZuaccLsSQK3IMBoVhaLdm4wktk51WtarQYt6UTSOiSSsCt7wHky2pmdxx+SlrEjZz5jeLXhw\ncHsiw/WXEgRx+AGc164hd1/Qhue+3kDn2BjG9olzuyRXTVqwlee/2cDw+FjuH1j63TAiQkxUODFR\n4bRuVOuUyxlj2H8472hAZmaTeiCH1Myi0DyQzcIte0k9kE1ewdGr8GEhQrO6UTSvG0WLevbvI8HY\nrG6U/pBW0KzlO3jo45WIwGvXxTOwo94AUFxQhx/AhPPOYEXKfv7yxVo6NImhR1xdt0tyxZcrd/Lo\nZ6sY0K4hT1/ZydG9YBGhdlQEtaMiaHvaqUOysNCwKzOb39Kz2JZ+iK17D7Et/RC/pWexZOs+Dhw3\nPrNxTOTvwdiiKBRb1K1B83pRnhqSUVaHcwuY+PlqJi9Kpmvz2rw0qiuxdfS89/ECemIDX2Vm53H5\ny/PJzM7j8zvO4bSYyErZblXxy6Z0xryziE6xMUy6qWeVPBdnjGHfobyjwZh+iK17s+zf6YdOaF1Q\nJyqc5vVq0KJuFC3rRdmv60XRom4UDWpV8+wpjl93H+D2j5awYfdBxvdvxT0XtamSc+n5kydmdSmL\nX3cf4PJX5tPmtFpMGdeLamFVLwD8YfWO/Vz9+gJOi4lk2vje1I6KcLukcsnKyWfb3kNsTS8KxGJ7\njTsyDlNY7Ns4KiKU5kWH0w2jq1G7egS1o8Lt3mn1cOrUCCemegR1osKJqR4eFOcdjTFMS0zhsZmr\nqBERxnMjz6K/R4d5afidxJcrd3Lbh0u4pmdz/npFp0rdthu2pR9i2Gs/Ex4izPi/s2kcU93tkvwi\nN7+Q7RmHjwZj+iG2Fe01pmflknEo95hwPF6tamHUrhF+YkhGhRNzXGDWjgqnTlQE0ZFhVSY0D2Tn\n8cinq/hs2Q7OblWPF0aeRcNobx3dFOeJKa3KalCnxozv34rXvt9El9gYRnZv7nZJfrPnYA7Xv7OQ\nvIJCJt/SO2iDDyAiLIS4+jWIO8UMIIWFhgM5+ew/lMe+Q7lkHM4j41AuGYfyyCh6bn/Rc/sO5ZGy\n7/Dvz5W0b1ArMow6UccGZo1qYVQLC6FaeAjVwkKJLPq7WlhI0fPFvg4LLVqu2DLHLV/a4fuq7fuZ\n8NEStu09xD0XtuH/zjvDpwlHlcfCD+C+i9uyesd+Hv10NW1Pi+asU8wnFsgO5uQz9t1F7MrM5qNb\nenFGw1NfhPCCkBAhpro9xG1ez/cT/4WFhgPZ+b8H5r5Duew/dDQk9xc9l3Eoj4zDeWxNzyIrp4Cc\n/AJy8gvJPckYybKKCDt1OEaEhbBsWwb1akYwZVxvz17MKy9PHfYesS8rl0tf+olCY5h1R1/qOzxZ\no5ty8gu48b3FLNi8l7euT+C8dg3dLsmzCgsNuQWF5OQX2kDMK/Z1fmHR46Kv8wvJySv2tY/LN6sb\nxcOD21OnRmCey/UHPewtQZ2iHsDDXv2ZCR8tYdJNPavM+ZuKKCw03DN1OfM3pvPP4V00+FwWEiJE\nhoQWjVfUoTlVTeD/xJdTx6YxPH2l7QH89JeB3wPYGMOfZ63m8xU7eWhwO4bFe/u+TaVK48k9vyOu\n7BbLipT9vP3TFjrHxjD0rKZul1Rur3y3kfd/2cot58Qxrl8rt8tRqsrz7J7fEQ9f0p4eLety/4wV\nrN2Z6XY55TJl0Tae/WoDV3ZtyoOD2rtdjlIBwfPhFx4awsvXdiWmeji3fpBExqHc0t9UhXy1ehcP\nfbKSc9s24JmrOgd93wWlnOL58ANoWCuSf18bbyd6nLKMgpJGxFYhi7bs5Y7JS+kcW5t/X9vNc7cx\nKVUR+tNSJL5FHZ4Ycibfb0jjhW82uF1OqdbtyuSm9xcTW6c6747trhOMKlVGGn7FXNOjOSMSYnlp\n3kbmrt5V+htckrz3ENe/vYgaEWH856aeOsZLqXLQ8CtGRJg4tCNdYmO4Z+pyNqZWvR7A6QdzGPPO\nIrLzCnj/xh40rR28t60p5U8afsc50gO4WlgIV7wyn4c/Wcny5Iwq0QozKyefG99bzPaMw7wztnuJ\nc+cppUqmJ4pOoknt6nx0Sy9e/34TM5ak8OHCbbRtVIvhCbFc0bUp9Vy4HS43v5Dxk5JYtSOT16+L\nJ6Gl3sepVEV48t7essjMzuPz5TuZmpjMsuQMwkKEC9o3YkT3WPq1blApt8UVFhrunrqMz5bt4O9X\ndWZEQjO/b1OpQKX39jokOjKca3o255qezdmw+wDTEpP5eMl25qzeRcNa1RgWH8vw+Fi/dcMyxvCX\nL9by2bId/GlgWw0+pRyie37lkFdQyLx1qUxLTOa79WkUFBq6t6zD8PhmDO7cmJoONv9+9X+beGbO\nOm7o05LHLu3g2enZlfKVozM5i8hA4F9AKPCWMeZvx70+FvgHsL3oqZeNMW+VtM5ADr/iUjOz+Xjp\ndqYmJrM5LYuoiFAu6dSYEd2bkdCiToXCampiMn+avoIhXZrwwsiz9O4NpXzgWPiJSCiwAbgQSAEW\nA6OMMWuKLTMWSDDGTPC1wGAJvyOMMSzZlsG0xGRmLd9BVm4BcfVrMDwhlmHdYmlUxmnFv1mzm1sn\nJXF2q3q8PaY7EWF6YV4pXzh5zq8HsNEYs7loxVOAocCaEt/lMSJCfIs6xLeow2OXdWD2yl1MTUzm\n73PW8+zc9ZzbtiEjEmI5v12jUoMsaetebv9oCWc2iebV6+I1+JTyA1/CrymQXOxxCtDzJMsNE5F+\n2L3Eu40xyccvICLjgHEAzZsHb/+MqIgwroqP5ar4WLbsyWJ6UjLTk1IYPymVujUiuKJrU4YnxNLu\ntOgT3rth9wFufC+RJrXtbWtOnj9USh3ly2HvVcBAY8zNRY9HAz2LH+KKSD3goDEmR0RuBUYaY84v\nab3BdthbmoJCww+/pjEtMZmv1+wmr8DQOTaG4QnNGNKlCTHVw9mecZhh//6ZQmOYcdvZNKurjaaV\nKisnD3u3A8XHV8Ry9MIGAMaY9GIP3wL+7kuRXhIaIpzXtiHntW3I3qxcPlu2nf8uTubRT1fxl8/X\nMLDjaazavp+s3Hym3tpbg08pP/Ml/BYDrUUkDht6VwPXFF9ARBobY3YWPRwCrHW0yiBTt0YEN/SJ\nY+zZLVm9I5Opicl8unQ72fmFfHBjD9o3PvFwWCnlrFLDzxiTLyITgLnYoS7vGGNWi8hEINEYMxO4\nU0SGAPnAXmCsH2sOGiJCx6YxdGwaw0OD25OZnUfDWt5tNq1UZdJBzkqpoOLrOT8dQ6GU8iQNP6WU\nJ2n4KaU8ScNPKeVJGn5KKU/S8FNKeZKGn1LKkzT8lFKepOGnlPIkDT+llCe5dnubiKQBW8v4tvrA\nHj+UU1UE++eD4P+M+vnc18IY06C0hVwLv/IQkURf7tkLVMH++SD4P6N+vsChh71KKU/S8FNKeVKg\nhd8bbhfgZ8H++SD4P6N+vgARUOf8lFLKKYG256eUUo7Q8FNKeVJAhJ+IDBSR9SKyUUQecLsep4lI\nMxH5TkTWiMhqEfmD2zX5g4iEishSEfnc7Vr8QURqi8h0EVknImtFpLfbNTlJRO4u+v5cJSKTRSSg\nG85U+fATkVDgFWAQ0AEYJSId3K3KcfnAPcaYDkAv4PYg/IwAfyC4O/v9C5hjjGkHdCGIPquINAXu\nBBKMMR2xzcyudreqiqny4Qf0ADYaYzYbY3KBKcBQl2tylDFmpzFmSdHXB7A/NE3drcpZIhILXILt\n6xx0RCQG6Ae8DWCMyTXGZLhblePCgOoiEgZEATtcrqdCAiH8mgLJxR6nEGTBUJyItAS6AgvdrcRx\nLwB/AgrdLsRP4oA04N2iQ/u3RKSG20U5xRizHXgW2AbsBPYbY75yt6qKCYTw8wwRqQnMAO4yxmS6\nXY9TRORSINUYk+R2LX4UBnQDXjXGdAWygKA5Py0idbBHXHFAE6CGiFznblUVEwjhtx1oVuxxbNFz\nQUVEwrHB96Ex5mO363FYH2CIiPyGPW1xvohMcrckx6UAKcaYI3vs07FhGCwuALYYY9KMMXnAx8DZ\nLtdUIYEQfouB1iISJyIR2JOsM12uyVEiIthzRWuNMc+5XY/TjDEPGmNijTEtsf9/84wxAb3XcDxj\nzC4gWUTaFj01AFjjYklO2wb0EpGoou/XAQT4BZ0wtwsojTEmX0QmAHOxV5jeMcasdrksp/UBRgMr\nRWRZ0XMPGWNmu1iTKrs7gA+LfklvBm5wuR7HGGMWish0YAl2dMJSAvxWN729TSnlSYFw2KuUUo7T\n8FNKeZKGn1LKkzT8lFKepOGnlPIkDT+llCdp+CmlPOn/AQnHl7tdbbkZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f145563c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(dloss_vec)\n",
    "plt.plot(gloss_vec)\n",
    "plt.legend(['dloss','gloss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both loss functions seem stable, and more or less at equilibrium, which is the desired behavior for a GAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Images After First Epoch\n",
    "\n",
    "Let's take a look at a sample of generated images after the 1st epoch:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"dcgan_generated_image_epoch_DeVore_final_1.png\",width=800,height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after just a single epoch, many of the generated images resemble actual numbers. That being said, there is plenty of room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Images After Tenth Epoch\n",
    "\n",
    "Let's see how the fully trained generator compares by looking at the images generated after the 10th and final epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dcgan_generated_image_epoch_DeVore_final_10.png\",width=800,height=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look much better, and are nearly indistinguishable from handwritten digits. The results are particularly impressive since the network was trained using only 10 iterations of the training set, and in just over 10 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conceptual Overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The structure of the GAN is different from anything we've seen so far. Rather than a single network, the GAN is actually composed of two networks. These networks, known as the generator and discriminator, have an adversarial relationship with one another (hence the name). In this exercise, both the generator and discriminator were convolutional neural networks, although this doesn't have to be the case. The generators job is to fool the discriminator by producing images that are indistinguishable from real images from a training set, and the discriminators job is to not be fooled by the generators attempts at forgery.\n",
    "\n",
    "One other major difference is that LeakyRelu activation functions are used for both networks. Sparsity is often your friend when it comes to deep learning, but not for GANs. Using the LeakyRelu allows for small negative outputs, as opposed to a standard Relu which would output zeros as a response to any negative input.\n",
    "\n",
    "The form of the generator network is rather unique. The input consists of a random sample of a predetermined size from a Gaussian distribution. This input is fed to a dense layer whose output is reshaped to a square tensor half the size of the output image (with some number of filters, in our case 32). This feature map tensor is passed through a convolution layer and then upsampled to the output image size. After several convolutions with varying numbers of filters (either 32 or 64 here), an image is produced as output from the generator with the proper size (in our case it's a 28x28x1). The final activation function is a hyperbolic tangent (tanh), which maps all values from -1 to 1.\n",
    "\n",
    "For the discriminator, the network structure looks much more familiar. The input is an image (28x28x1 here), and after several strided convolutions and a dropout layer, a final dense layer with a single node and sigmoid activation function outputs a probability of the image it just processed being real.\n",
    "\n",
    "The structure of the actual GAN is rather simple. The input is random noise (the input to the generator), and the output is the prediction made by the discriminator, which has been fed the output from the generator which has been fed the random noise input. Within the GAN, the discriminator is not trainable (this is very important!).\n",
    "\n",
    "The GAN training consists of two phases, which are repeated for each batch of images within each epoch. First, images are created by the generator and labeled as 'fake'. These are combined with images from the training set, which are labeled as 'real'. The discriminator is trained using these images. First, the fake images are just random noise, but they get better over time (as the generator learns how to produce more convincing images), which makes the discriminator better at spotting fake images. Second, another batch of images is created by the generator, except these are labeled as 'real' (to try and fool the discriminator). These images are fed to the discriminator within the GAN (recall that it's weights are frozen), and the weights of the generator are updated so that it is better able to fool the discriminator over time.\n",
    "\n",
    "During training, dual loss functions are monitored (from the discriminator and the GAN, which is really just the generator). There is no convergence here, rather the loss functions come to an equilibrium with one another. This state represents the generator producing images that are so convincing that the discriminator can't tell if they are real or not, and it settles to an accuracy of roughly 50% (it is no better than random guesses as to the authenticity of an image).\n",
    "\n",
    "Overall, I was really impressed with the generators ability to create convincing handwritten digit images after only 10 epochs of training. The biggest challenges encountered were that I made the network too complex at first (I modeled it after an example in the textbook which was used to generate more detailed color images). After some debugging I found that the model was overfitting after only 10 iterations, during the first epoch. Scaling back the number of filters created in the convolution layers helped immensely, and soon I was generating digits. The other challenge was that my generated numbers often had dark borders around the edges of the image. The numbers themselves looked good, but the border artifacts were distracting. Careful tuning of the filter sizes and stride lengths helped eliminate this phenomenon. Admittedly, this was an extremely simple implementation of a GAN, and they are notoriously hard to train. Still, these results were encouraging and give me the confidence to try a harder problem (like color images!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
